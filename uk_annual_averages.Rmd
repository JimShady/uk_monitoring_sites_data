---
title: "UK Annual Averages"
author: "James David Smith"
date: "26 February 2019"
output: html_document
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "docs") })
---

```{r setup, include=FALSE}
rm(list = ls())

library(tidyverse)
library(openair)
library(lubridate)
library(gganimate)
library(sf)
library(gifski)

years <- 2017

```

Import air quality data from KCL and calculate annual means + completeness by site code and pollutant.

```{r}

suppressWarnings(dir.create('site_data'))

kcl           <- importMeta(source = 'kcl') %>% group_by(code) %>% summarise() %>% mutate(code = as.character(code)) %>% head(100)

kcl_data      <- list()

for (i in 1:nrow(kcl)) {
  
  kcl_data[[i]] <- suppressWarnings(importKCL(site = kcl$code[i], pollutant = 'all', year = years))
  
  #closeAllConnections()
  
}

kcl_data[sapply(kcl_data, is.null)] <- NULL

result_data <- unique(unlist(lapply(kcl_data, names))) %>% 
                as_tibble() %>% 
                rownames_to_column() %>% 
                spread(value, rowname, fill=NA) %>%
                mutate(site = as.character(site))

result_data[1,] <- NA

for (i in 1:length(kcl_data)) {
  
  result_data <- suppressWarnings(bind_rows(as_tibble(kcl_data[[i]]), result_data))
  
}

rm(kcl_data)

#save(result_data, file='kcl_results.Rdata')
#load('kcl_results.Rdata')

kcl_means <- result_data %>% 
              select(-pm10_raw, -so2, -v10, -v2.5, -nv10, -nv2.5) %>% 
              mutate(date = year(date)) %>%
              group_by(site, date, code) %>% 
              summarise_all(funs(count = sum(!is.na(.)), 
                                 mean  = mean(., na.rm=T)))

# Calculate numbers of days of exceedance per site. Decided need to have >= 19 hours of data in a day for the mean to be valid
# 
kcl_pm10days <- result_data %>%
                  select(site, date, code, pm10) %>%
                  group_by(site, format(date, '%Y-%m-%d'), code) %>%
                  summarise_all(funs(count = sum(!is.na(.)), 
                                 mean  = mean(., na.rm=T))) %>%
                  rename(day = `format(date, "%Y-%m-%d")`) %>%
                  select(site, day, code, pm10_count, pm10_mean) %>%
                  filter(pm10_count >= 17 & pm10_mean > 50) %>%
                  select(site, day, code, pm10_mean) %>%
                  group_by(site, substr(day,1,4), code) %>%
                  summarise(exceedance_days = n()) %>%
                  ungroup() %>%
                  rename(date         = `substr(day, 1, 4)`,
                         mean         = exceedance_days) %>%
                  mutate(pollutant  = 'pm10d',
                         date       = as.numeric(date),
                         hours      = NA,
                         measurements = NA,
                         percentage = NA)
                  
  
counts <- kcl_means %>% 
          select(site, date, code, nox_count, no2_count, o3_count, pm10_count, co_count, pm25_count) %>% 
          gather(pollutant, measurements, nox_count, no2_count, o3_count, pm10_count, co_count, pm25_count) %>%
          mutate(pollutant = gsub("_.*", "", pollutant))


means <- kcl_means %>% 
  select(site, date, code, nox_mean, no2_mean, o3_mean, pm10_mean, co_mean, pm25_mean) %>% 
  gather(pollutant, mean, nox_mean, no2_mean, o3_mean, pm10_mean, co_mean, pm25_mean) %>%
  mutate(pollutant = gsub("_.*", "", pollutant))

rm(result_data)

kcl_result <- left_join(means, counts, by = c('site' = 'site', 'date' = 'date', 'code' = 'code', 'pollutant' = 'pollutant')) %>% #left_join
          select(site, date, code, pollutant, mean, measurements) %>%
          filter(!is.na(mean)) %>% 
          ungroup()

hours <- tibble(years_to_consider = c(2013, 2014, 2015, 2016, 2017, 2018, 2019),
                hours = c(8761,8761,8761,8785,8761,8761,8761))

hours <- filter(hours, years_to_consider %in% years) %>% rename(year = years_to_consider)

kcl_result            <- left_join(kcl_result, hours, by = c('date' = 'year'))
kcl_result$percentage <- 100*(kcl_result$measurements / kcl_result$hours)

kcl_result    <- bind_rows(kcl_result, kcl_pm10days)

rm(counts, hours, kcl, kcl_means, means, kcl_pm10days,i)

```

Import air quality data from AURN and calculate annual means + completeness by site code and pollutant.

```{r, message=F, warning=F, echo=T, results='hide'}

aurn           <- importMeta(source = 'aurn') %>% group_by(code) %>% summarise() %>% mutate(code = as.character(code)) %>% head(100)

aurn_data      <- list()

for (i in 1:nrow(aurn)) {
  
  aurn_data[[i]] <- suppressWarnings(importAURN(site = aurn$code[i], pollutant = 'all', year = years))
  
  #closeAllConnections()
  
  print(i)
  
}

aurn_data[sapply(aurn_data, is.null)] <- NULL

result_data <- unique(unlist(lapply(aurn_data, names))) %>% 
                as_tibble() %>% 
                rownames_to_column() %>% 
                spread(value, rowname, fill=NA) %>%
                mutate(site = as.character(site))

result_data[1,] <- NA

for (i in 1:length(aurn_data)) {
  
  result_data <- suppressWarnings(bind_rows(as_tibble(aurn_data[[i]]), result_data))
  
}

save(result_data, file='aurn_results.Rdata')
#load('aurn_results.Rdata')

rm(aurn_data)

aurn_means <- result_data %>% 
              select(-wd, -ws,-nv10,-v10,-nv2.5,-v2.5) %>% 
              mutate(date = year(date)) %>%
              rename(pm25 = pm2.5) %>%
              group_by(site, date, code) %>% 
              summarise_all(funs(count = sum(!is.na(.)), 
                                 mean  = mean(., na.rm=T)))

# Calculate numbers of days of exceedance per site. Decided need to have >= 19 hours of data in a day for the mean to be valid
# 
aurn_pm10days <- result_data %>%
                  select(site, date, code, pm10) %>%
                  group_by(site, format(date, '%Y-%m-%d'), code) %>%
                  summarise_all(funs(count = sum(!is.na(.)), 
                                 mean  = mean(., na.rm=T))) %>%
                  rename(day = `format(date, "%Y-%m-%d")`) %>%
                  select(site, day, code, pm10_count, pm10_mean) %>%
                  filter(pm10_count >= 17 & pm10_mean > 50) %>%
                  select(site, day, code, pm10_mean) %>%
                  group_by(site, substr(day,1,4), code) %>%
                  summarise(exceedance_days = n()) %>%
                  ungroup() %>%
                  rename(date         = `substr(day, 1, 4)`,
                         mean         = exceedance_days) %>%
                  mutate(pollutant  = 'pm10d',
                         date       = as.numeric(date),
                         hours      = NA,
                         measurements = NA,
                         percentage = NA)
                  
  
counts <- aurn_means %>% 
  select(site, date, code, nox_count, no2_count, o3_count, pm10_count, co_count, pm25_count) %>% 
  gather(pollutant, measurements, nox_count, no2_count, o3_count, pm10_count, co_count, pm25_count) %>%
  mutate(pollutant = gsub("_.*", "", pollutant))


means <- aurn_means %>% 
  select(site, date, code, nox_mean, no2_mean, o3_mean, pm10_mean, co_mean, pm25_mean) %>% 
  gather(pollutant, mean, nox_mean, no2_mean, o3_mean, pm10_mean, co_mean, pm25_mean) %>%
  mutate(pollutant = gsub("_.*", "", pollutant))

rm(result_data)

aurn_result <- left_join(means, counts, by = c('site' = 'site', 'date' = 'date', 'code' = 'code', 'pollutant' = 'pollutant')) %>% #left_join
          select(site, date, code, pollutant, mean, measurements) %>%
          filter(!is.na(mean)) %>% 
          ungroup()

hours <- tibble(years_to_consider = c(2013, 2014, 2015, 2016, 2017, 2018, 2019),
                hours = c(8761,8761,8761,8785,8761,8761,8761))

hours <- filter(hours, years_to_consider %in% years) %>% rename(year = years_to_consider)

aurn_result            <- left_join(aurn_result, hours, by = c('date' = 'year'))
aurn_result$percentage <- 100*(aurn_result$measurements / aurn_result$hours)

aurn_result    <- bind_rows(aurn_result, aurn_pm10days)

rm(counts, hours, aurn, aurn_means, means, aurn_pm10days,i)

```

Combine data

```{r, message=F, warning=F, echo=F}

kcl_result$source  <- 'importKCL'
aurn_result$source <- 'importAURN'

result <- bind_rows(kcl_result, aurn_result)
rm(kcl_result, aurn_result)

result <- select(result, -measurements, -hours) %>% rename(capture_rate = percentage)

head(result)

```

Identify London sites

```{r, message=F, warning=F, echo=F}

box   <- st_read('laei_box.geojson',quiet=TRUE) %>% mutate(name = 'LAEIBox')

sites <- bind_rows(mutate(importMeta(source = 'kcl'), source = 'importKCL'), 
                   mutate(importMeta(source = 'aurn'), source = 'importAURN')) %>% 
          as_tibble() %>% 
          dplyr::select(code, site, latitude, longitude, site.type, source) %>% 
          st_as_sf(coords = c('longitude', 'latitude'), na.fail = F) %>%
          st_set_crs(4326)

sites <- st_join(sites, box, join = st_intersects)

rm(box)

result <- left_join(result, sites, by = c('site' = 'site', 'source' = 'source', 'code' = 'code')) %>% st_as_sf()

result[is.na(result$name), 'name'] <- 'Non-London'

rm(sites)

```

Where there is data from KCL and also from AURN, just keep the KCL data

```{r}

result <- result %>% 
              select(date, code, pollutant) %>% 
              st_drop_geometry() %>% 
              group_by(date, code, pollutant) %>% 
              summarise(n()) %>% 
              rename(count = 'n()') %>% 
              filter(count > 1) %>% 
              mutate(duplicate = 'Y') %>% 
              select(-count) %>%
              mutate(source = 'importAURN') %>%
              left_join(result, ., by = c('date' = 'date', 'pollutant' = 'pollutant', 'code' = 'code', 'source' = 'source'))

result[is.na(result$duplicate), 'duplicate'] <- 'N'

```

Make graphs

```{r, message=F, warning=F, echo=F}
#cols                <- c('Non-London' = 'yellow', 'LAEIBox' = 'red')

#plot <- ggplot(data = filter(result, pollutant %in% c('pm10', 'pm25', 'no2') & capture_rate > 70 & duplicate == 'N'), aes(date, mean, group=code)) +
#  geom_path(alpha=0.4,aes(colour=name)) +
#  scale_color_manual(values = cols) +
#  #geom_smooth(data = filter(result, pollutant %in% c('pm10', 'pm25', 'no2') & percentage > 70), aes(date, mean, group=1),
#  #            colour = 'white', fill = 'white') +
#  facet_wrap(.~toupper(pollutant), scales = 'free_y', ncol = 1) +
#  theme(legend.position   = 'none',
#        panel.grid        = element_blank(),
#        panel.background  = element_rect(fill = 'black'),
#        axis.title.x      = element_blank(),
#        strip.background  = element_blank(),
#        strip.text.x      = element_text(angle = 0, hjust = 0, colour='black', size=12),
#        axis.text         = element_text(size = 12, colour = 'black')) +
# ylab (expression(paste("Concentration (", mu, g, "/", m^3, ")", sep=""))) +
#  transition_reveal(date) +
#  ease_aes('linear')

#print(plot)
```

Write data

```{r, message=F, warning=F, echo=F}

result %>% 
  st_transform(27700) %>% 
  st_write(paste0('site_means_', Sys.Date(), '.csv'), layer_options = "GEOMETRY=AS_XY")

head(result)

```